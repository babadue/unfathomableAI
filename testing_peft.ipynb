{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f9de03e-fcbf-4946-b25a-667abcfa1d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mydma\\miniconda3\\envs\\myenv2\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig\n",
    "import torch\n",
    "\n",
    "# PEFT adapter\n",
    "peft_adapter=\"./flan_t5_fine_tuned_peft-local_5e\"   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ad03c9-12c9-4661-876b-b916f3c1175d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mydma\\miniconda3\\envs\\myenv2\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base, \n",
    "                                       peft_adapter, \n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "679baac5-27ba-41c3-923d-56a0706d837a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset count:  18\n"
     ]
    }
   ],
   "source": [
    "# Given testset\n",
    "testset = [{'country': 'USA', 'capital': 'Washington'}, \n",
    "           {'country': 'China', 'capital': 'Beijing'},\n",
    "           {'country': 'France', 'capital': 'Paris'},\n",
    "           {'country': 'England', 'capital': 'London'},\n",
    "           {'country': 'Germany', 'capital': 'Berlin'},\n",
    "           {'country': 'Japan', 'capital': 'Tokyo'},\n",
    "           {'country': 'Spain', 'capital': 'Madrid'},       \n",
    "           {'country': 'Mexico', 'capital': 'Mexico City'},\n",
    "           {'country': 'Canada', 'capital': 'Ottawa'},\n",
    "           {'country': 'Thailand', 'capital': 'Bangkok'}, \n",
    "           {'country': 'Italy', 'capital': 'Rome'},       \n",
    "           {'country': 'Russia', 'capital': 'Moscow'},\n",
    "           {'country': 'Venezuela', 'capital': 'Caracas'},\n",
    "           {'country': 'Vietnam', 'capital': 'Hanoi'}, \n",
    "           {'country': 'Turkey', 'capital': 'Ankara'},       \n",
    "           {'country': 'Brazil', 'capital': 'Brasilia'},\n",
    "           {'country': 'Honduras', 'capital': 'Tegucigalpa'},\n",
    "           {'country': 'Hungary', 'capital': 'Budapest'} \n",
    "          ]\n",
    "\n",
    "print('testset count: ',len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e8bbc1-ab3a-42c2-ba56-4433be07a1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: What is the capital of USA  ( Washington )\n",
      "Model's Response: Washington \n",
      "\n",
      "Input: What is the capital of China  ( Beijing )\n",
      "Model's Response: Beijing \n",
      "\n",
      "Input: What is the capital of France  ( Paris )\n",
      "Model's Response: Paris \n",
      "\n",
      "Input: What is the capital of England  ( London )\n",
      "Model's Response: London \n",
      "\n",
      "Input: What is the capital of Germany  ( Berlin )\n",
      "Model's Response: Berlin \n",
      "\n",
      "Input: What is the capital of Japan  ( Tokyo )\n",
      "Model's Response: Tokyo \n",
      "\n",
      "Input: What is the capital of Spain  ( Madrid )\n",
      "Model's Response: Madrid \n",
      "\n",
      "Input: What is the capital of Mexico  ( Mexico City )\n",
      "Model's Response: Mexico \n",
      "\n",
      "Input: What is the capital of Canada  ( Ottawa )\n",
      "Model's Response: Ottawa \n",
      "\n",
      "Input: What is the capital of Thailand  ( Bangkok )\n",
      "Model's Response: Bangkok \n",
      "\n",
      "Input: What is the capital of Italy  ( Rome )\n",
      "Model's Response: Rome \n",
      "\n",
      "Input: What is the capital of Russia  ( Moscow )\n",
      "Model's Response: Moscow \n",
      "\n",
      "Input: What is the capital of Venezuela  ( Caracas )\n",
      "Model's Response: Caracas \n",
      "\n",
      "Input: What is the capital of Vietnam  ( Hanoi )\n",
      "Model's Response: Hanoi \n",
      "\n",
      "Input: What is the capital of Turkey  ( Ankara )\n",
      "Model's Response: Istanbul \n",
      "\n",
      "Input: What is the capital of Brazil  ( Brasilia )\n",
      "Model's Response: Rio \n",
      "\n",
      "Input: What is the capital of Honduras  ( Tegucigalpa )\n",
      "Model's Response: Honduras \n",
      "\n",
      "Input: What is the capital of Hungary  ( Budapest )\n",
      "Model's Response: Budapest \n",
      "\n",
      "Number of correct responses: 14 out of 18\n",
      "Percentage of correct responses: %77.78\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "question=\"What is the capital of \"\n",
    "# iterate through entire testset to inferring the model for capitals\n",
    "for country_dict in testset:\n",
    "    a_country=country_dict['country']\n",
    "    # input_prompt=question + a_country +'?'\n",
    "    input_prompt=question + a_country    # the inferring seemed to be better without question mark\n",
    "    \n",
    "    input_ids = tokenizer(input_prompt, return_tensors=\"pt\").input_ids  \n",
    "    \n",
    "    peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Input: {input_prompt}  ( {country_dict['capital']} )\")\n",
    "    print(\"Model's Response:\", peft_model_text_output, '\\n')\n",
    "\n",
    "    if country_dict['capital'].lower() == peft_model_text_output.lower():\n",
    "        correct +=1\n",
    "    \n",
    "print(f\"Number of correct responses: {correct} out of {len(testset)}\")\n",
    "\n",
    "# print(\"Percentage of correct responses: %.2f%%\" % round((correct / len(testset) * 100), 2))\n",
    "print(f\"Percentage of correct responses: %{round((correct / len(testset) * 100), 2)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e7e97-5cc3-45f0-a47f-78a84ee7398a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
