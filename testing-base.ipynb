{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821ebff6-f213-4f8d-b18f-9504406596e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mydma\\miniconda3\\envs\\myenv2\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\mydma\\miniconda3\\envs\\myenv2\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\mydma\\miniconda3\\envs\\myenv2\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fc346d-2d9a-4b74-aa5b-dc56a58aac2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset count:  18\n"
     ]
    }
   ],
   "source": [
    "# Given testset\n",
    "testset = [{'country': 'USA', 'capital': 'Washington'}, \n",
    "           {'country': 'China', 'capital': 'Beijing'},\n",
    "           {'country': 'France', 'capital': 'Paris'},\n",
    "           {'country': 'England', 'capital': 'London'},\n",
    "           {'country': 'Germany', 'capital': 'Berlin'},\n",
    "           {'country': 'Japan', 'capital': 'Tokyo'},\n",
    "           {'country': 'Spain', 'capital': 'Madrid'},       \n",
    "           {'country': 'Mexico', 'capital': 'Mexico City'},\n",
    "           {'country': 'Canada', 'capital': 'Ottawa'},\n",
    "           {'country': 'Thailand', 'capital': 'Bangkok'}, \n",
    "           {'country': 'Italy', 'capital': 'Rome'},       \n",
    "           {'country': 'Russia', 'capital': 'Moscow'},\n",
    "           {'country': 'Venezuela', 'capital': 'Caracas'},\n",
    "           {'country': 'Vietnam', 'capital': 'Hanoi'}, \n",
    "           {'country': 'Turkey', 'capital': 'Ankara'},       \n",
    "           {'country': 'Brazil', 'capital': 'Brasilia'},\n",
    "           {'country': 'Honduras', 'capital': 'Tegucigalpa'},\n",
    "           {'country': 'Hungary', 'capital': 'Budapest'} \n",
    "          ]\n",
    "\n",
    "print('testset count: ',len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c9978f9-4ff2-4cea-ba48-fc12655abc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: What is the capital of USA  ( Washington )\n",
      "Model's Response: san francisco \n",
      "\n",
      "Input: What is the capital of China  ( Beijing )\n",
      "Model's Response: qingdao \n",
      "\n",
      "Input: What is the capital of France  ( Paris )\n",
      "Model's Response: london \n",
      "\n",
      "Input: What is the capital of England  ( London )\n",
      "Model's Response: london \n",
      "\n",
      "Input: What is the capital of Germany  ( Berlin )\n",
      "Model's Response: berlin \n",
      "\n",
      "Input: What is the capital of Japan  ( Tokyo )\n",
      "Model's Response: nagasaki \n",
      "\n",
      "Input: What is the capital of Spain  ( Madrid )\n",
      "Model's Response: san marino \n",
      "\n",
      "Input: What is the capital of Mexico  ( Mexico City )\n",
      "Model's Response: san juan \n",
      "\n",
      "Input: What is the capital of Canada  ( Ottawa )\n",
      "Model's Response: Ottawa \n",
      "\n",
      "Input: What is the capital of Thailand  ( Bangkok )\n",
      "Model's Response: taipei \n",
      "\n",
      "Input: What is the capital of Italy  ( Rome )\n",
      "Model's Response: rome \n",
      "\n",
      "Input: What is the capital of Russia  ( Moscow )\n",
      "Model's Response: tbilisi \n",
      "\n",
      "Input: What is the capital of Venezuela  ( Caracas )\n",
      "Model's Response: san juan \n",
      "\n",
      "Input: What is the capital of Vietnam  ( Hanoi )\n",
      "Model's Response: trang hnh \n",
      "\n",
      "Input: What is the capital of Turkey  ( Ankara )\n",
      "Model's Response: stanbul \n",
      "\n",
      "Input: What is the capital of Brazil  ( Brasilia )\n",
      "Model's Response: so paulo \n",
      "\n",
      "Input: What is the capital of Honduras  ( Tegucigalpa )\n",
      "Model's Response: san juan \n",
      "\n",
      "Input: What is the capital of Hungary  ( Budapest )\n",
      "Model's Response: budapest \n",
      "\n",
      "Number of correct responses: 5 out of 18\n",
      "Percentage of correct responses: %27.78\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "question=\"What is the capital of \"\n",
    "# iterate through entire testset to inferring the model for capitals\n",
    "for country_dict in testset:\n",
    "    a_country=country_dict['country']\n",
    "    # input_prompt=question + a_country  +'?'\n",
    "    input_prompt=question + a_country    # the inferring results are the same with or without question mark\n",
    "\n",
    "    # Tokenize and generate the model's response\n",
    "    input_encodings = tokenizer(input_prompt, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    output_ids = model.generate(input_encodings[\"input_ids\"])\n",
    "    \n",
    "    # Decode the generated output\n",
    "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Input: {input_prompt}  ( {country_dict['capital']} )\")\n",
    "    print(\"Model's Response:\", output_text, '\\n')\n",
    "\n",
    "    if country_dict['capital'].lower() == output_text.lower():\n",
    "        correct +=1\n",
    "    \n",
    "print(f\"Number of correct responses: {correct} out of {len(testset)}\")\n",
    "\n",
    "# print(\"Percentage of correct responses: %.2f%%\" % round((correct / len(testset) * 100), 2))\n",
    "print(f\"Percentage of correct responses: %{round((correct / len(testset) * 100), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66904c19-545f-469e-8e27-c3291d515f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
