{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6ebcab8-abab-42c5-9a5a-f57c17ab3e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# output_dir=\"./flan_t5_fine_tuned_30e\"\n",
    "# output_dir=\"./flan_t5_fine_tuned_13e-1707830093\\checkpoint-1000\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "output_dir=\"./flan_t5_fine_tuned_10e_local\"   \n",
    "# output_dir=\"./flan_t5_fine_tuned_1000e_local\"\n",
    "\n",
    "# # Load the fine-tuned model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(output_dir)  # Specify the correct path to the fine-tuned model\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)  # Specify the correct path to the fine-tuned mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17fc346d-2d9a-4b74-aa5b-dc56a58aac2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset count:  18\n"
     ]
    }
   ],
   "source": [
    "# Given testset\n",
    "testset = [{'country': 'USA', 'capital': 'Washington'}, \n",
    "           {'country': 'China', 'capital': 'Beijing'},\n",
    "           {'country': 'France', 'capital': 'Paris'},\n",
    "           {'country': 'England', 'capital': 'London'},\n",
    "           {'country': 'Germany', 'capital': 'Berlin'},\n",
    "           {'country': 'Japan', 'capital': 'Tokyo'},\n",
    "           {'country': 'Spain', 'capital': 'Madrid'},       \n",
    "           {'country': 'Mexico', 'capital': 'Mexico City'},\n",
    "           {'country': 'Canada', 'capital': 'Ottawa'},\n",
    "           {'country': 'Thailand', 'capital': 'Bangkok'}, \n",
    "           {'country': 'Italy', 'capital': 'Rome'},       \n",
    "           {'country': 'Russia', 'capital': 'Moscow'},\n",
    "           {'country': 'Venezuela', 'capital': 'Caracas'},\n",
    "           {'country': 'Vietnam', 'capital': 'Hanoi'}, \n",
    "           {'country': 'Turkey', 'capital': 'Ankara'},       \n",
    "           {'country': 'Brazil', 'capital': 'Brasilia'},\n",
    "           {'country': 'Honduras', 'capital': 'Tegucigalpa'},\n",
    "           {'country': 'Hungary', 'capital': 'Budapest'} \n",
    "          ]\n",
    "\n",
    "print('testset count: ',len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcc50faf-6792-4686-b76d-c223d79b6671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: What is the capital of USA  ( Washington )\n",
      "Model's Response: Washington, D.C. \n",
      "\n",
      "Input: What is the capital of China  ( Beijing )\n",
      "Model's Response: qingdao \n",
      "\n",
      "Input: What is the capital of France  ( Paris )\n",
      "Model's Response: l'on d'or \n",
      "\n",
      "Input: What is the capital of England  ( London )\n",
      "Model's Response: london \n",
      "\n",
      "Input: What is the capital of Germany  ( Berlin )\n",
      "Model's Response: Berlin \n",
      "\n",
      "Input: What is the capital of Japan  ( Tokyo )\n",
      "Model's Response:  \n",
      "\n",
      "Input: What is the capital of Spain  ( Madrid )\n",
      "Model's Response: Madrid \n",
      "\n",
      "Input: What is the capital of Mexico  ( Mexico City )\n",
      "Model's Response: san juan \n",
      "\n",
      "Input: What is the capital of Canada  ( Ottawa )\n",
      "Model's Response: Ottawa \n",
      "\n",
      "Input: What is the capital of Thailand  ( Bangkok )\n",
      "Model's Response: Bangkok \n",
      "\n",
      "Input: What is the capital of Italy  ( Rome )\n",
      "Model's Response: Rome \n",
      "\n",
      "Input: What is the capital of Russia  ( Moscow )\n",
      "Model's Response: Yalta \n",
      "\n",
      "Input: What is the capital of Venezuela  ( Caracas )\n",
      "Model's Response: Buenos Aires \n",
      "\n",
      "Input: What is the capital of Vietnam  ( Hanoi )\n",
      "Model's Response: Hanoi \n",
      "\n",
      "Input: What is the capital of Turkey  ( Ankara )\n",
      "Model's Response: Istanbul \n",
      "\n",
      "Input: What is the capital of Brazil  ( Brasilia )\n",
      "Model's Response: Buenos Aires \n",
      "\n",
      "Input: What is the capital of Honduras  ( Tegucigalpa )\n",
      "Model's Response: Honduras \n",
      "\n",
      "Input: What is the capital of Hungary  ( Budapest )\n",
      "Model's Response: Budapest \n",
      "\n",
      "Number of correct responses: 8 out of 18\n",
      "Percentage of correct responses: %44.44\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "question=\"What is the capital of \"\n",
    "# iterate through entire testset to inferring the model for capitals\n",
    "for country_dict in testset:\n",
    "    a_country=country_dict['country']\n",
    "    # input_prompt=question + a_country +'?'\n",
    "    input_prompt=question + a_country   # the inferring seemed to be better without question mark\n",
    "    \n",
    "    # Tokenize and generate the model's response\n",
    "    input_encodings = tokenizer(input_prompt, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    output_ids = model.generate(input_encodings[\"input_ids\"])\n",
    "    \n",
    "    # Decode the generated output\n",
    "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Input: {input_prompt}  ( {country_dict['capital']} )\")\n",
    "    print(\"Model's Response:\", output_text, '\\n')\n",
    "\n",
    "    if country_dict['capital'].lower() == output_text.lower():\n",
    "        correct +=1\n",
    "    \n",
    "print(f\"Number of correct responses: {correct} out of {len(testset)}\")\n",
    "\n",
    "# print(\"Percentage of correct responses: %.2f%%\" % round((correct / len(testset) * 100), 2))\n",
    "print(f\"Percentage of correct responses: %{round((correct / len(testset) * 100), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539e6d98-12ef-4a14-b2bf-afb148c3058e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
